{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "333e6f29-cb9e-47e4-b3e3-36d2d91febe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Spark Session\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import from_json, col, expr, when , lit , window, current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, DoubleType, IntegerType, TimestampType, ArrayType\n",
    "\n",
    "# Create the Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Transaction Streamin Job\") \n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True)\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32b052e1-b17f-4f08-b1db-0894682ebf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fb394efbc5e2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Transaction Streamin Job</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x73a4e9d4ced0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check on spark object\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85b52c3b-53b8-4f97-b515-60c0fec79901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the JSON data\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"amount\", DoubleType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "    StructField(\"source\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3d95729-e257-4e9c-bc88-69076bd35ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the kafka_df to read from kafka\n",
    "kafka_df = (\n",
    "    spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9094\") \\\n",
    "    .option(\"subscribe\", \"transactions\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b0862ae-70e1-4bb5-b5d1-197fe01681ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d91f796-0856-426f-97e0-d9c44ecdefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize and create the value_df to read from kafka    \n",
    "value_df = kafka_df.select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"value\")).select(\"value.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fec67b6-3cff-40b1-8e81-bd969e4b5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "425acff0-ab23-4098-a89a-28a917c208f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1d8ea63-acdc-4093-aebb-2a0c683f6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the data\n",
    "validated_df = value_df.withColumn(\"error_reason\", \n",
    "                                   when(col(\"user_id\").isNull() | col(\"amount\").isNull() | col(\"timestamp\").isNull(), \"Missing mandatory fields\")\n",
    "                                   .when((col(\"amount\") < 1) | (col(\"amount\") > 10000000), \"Amount out of range\")\n",
    "                                   .when(~col(\"source\").isin(\"mobile\", \"web\", \"pos\"), \"Invalid source\")\n",
    "                                   .otherwise(None)\n",
    "                                  ).withColumn(\"is_valid\", col(\"error_reason\").isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa3198bf-6223-46ca-9237-fe50a1aa6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add watermark and drop duplicates\n",
    "valid_df = validated_df.filter(col(\"is_valid\") == True) \\\n",
    "                .withWatermark(\"timestamp\", \"3 minutes\") \\\n",
    "                .dropDuplicates([\"user_id\", \"timestamp\"])\n",
    "\n",
    "\n",
    "invalid_df = validated_df.filter(col(\"is_valid\") == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f83de4a5-c122-4823-9b8f-f6de9fc13653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tumbling window monitoring\n",
    "\n",
    "window_agg_df = valid_df \\\n",
    "                .groupBy(window(col(\"timestamp\"), \"1 minutes\")) \\\n",
    "                .count() \\\n",
    "                .select(current_timestamp().alias(\"timestamp\"), col(\"window.start\").alias(\"window_start\"), col(\"window.end\").alias(\"window_end\"), col(\"count\").alias(\"total_transactions\"))\n",
    "\n",
    "# window_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f79d6f74-663a-4c41-bfa3-6fc860b453ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "console_output_df = window_agg_df.select(\n",
    "                    current_timestamp().alias(\"timestamp\"), \n",
    "                    col(\"total_transactions\").alias(\"running_total\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7594b14-84da-468b-84c8-c3b7aa799dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write valid data to kafka\n",
    "\n",
    "query_console = console_output_df.writeStream \\\n",
    "                .outputMode(\"complete\") \\\n",
    "                .format(\"console\") \\\n",
    "                .option(\"truncate\", \"false\") \\\n",
    "                .start()\n",
    "\n",
    "valid_query = valid_df.selectExpr(\"to_json(struct(*)) as value\") \\\n",
    "                        .writeStream \\\n",
    "                        .format(\"kafka\") \\\n",
    "                        .option(\"kafka.bootstrap.servers\", \"kafka:9094\") \\\n",
    "                        .option(\"topic\", \"transactions_valid\") \\\n",
    "                        .option(\"checkpointLocation\", \"checkpoints/valid\") \\\n",
    "                        .start()\n",
    "\n",
    "invalid_dlq = invalid_df.selectExpr(\"to_json(struct(*)) as value\") \\\n",
    "                        .writeStream \\\n",
    "                        .format(\"kafka\") \\\n",
    "                        .option(\"kafka.bootstrap.servers\", \"kafka:9094\") \\\n",
    "                        .option(\"topic\", \"transactions_dlq\") \\\n",
    "                        .option(\"checkpointLocation\", \"checkpoints/dlq\") \\\n",
    "                        .start()\n",
    "                        \n",
    "spark.streams.awaitAnyTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c09c4c-ab64-4443-96b3-92b3b907789f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73043fca-ccd2-4712-b63f-b120bf718d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
